{
    "mode": "general_lm_eval",
    "wandb_project": "Gradient Descent",
    "wandb_run_name": "LLaMa-7B-CC_",
    "check_validation_only": false,
    "save_checkpoint": false,
    "do_init_eval": false,
    "train_set": "cc_llama.csv",
    "loss_fn": "mle",
    "valid_sets": [
        "piqa",
        "hellaswag",
        "ai2_arc",
        "ai2_arc",
        "super_glue",
        "winogrande",
        "math_qa"
    ],
    "valid_subset_path": [
        "",
        "",
        "ARC-Easy",
        "ARC-Challenge",
        "copa",
        "winogrande_s",
        ""
    ],
    "valid_type_path": [
        "validation",
        "validation",
        "validation",
        "validation",
        "validation",
        "validation",
        "validation"
    ],
    "train_batch_size": 1,
    "eval_batch_size": 1,
    "gradient_accumulation_steps": 1,
    "ngpu": 8,
    "learning_rate": 5e-7,
    "model_name_or_path": "meta-llama/Llama-2-7b-hf",
    "input_length": 512,
    "output_length": 512,
    "target_length": 200,
    "num_workers": 7,
    "fp16": true,
    "wandb_log": true
}
